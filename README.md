<div align="center">

# üèéÔ∏è Formula Student Autonomous Systems

**High-performance autonomous driving software for Formula Student Driverless competitions**

[![ROS 2](https://img.shields.io/badge/ROS-2-blue.svg)](https://docs.ros.org/en/humble/)
[![Python](https://img.shields.io/badge/Python-3.8+-yellow.svg)](https://www.python.org/)
[![C++](https://img.shields.io/badge/C++-17-orange.svg)](https://isocpp.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)]()

[Features](#-key-features) ‚Ä¢ [Architecture](#-system-architecture) ‚Ä¢ [Installation](#-getting-started) ‚Ä¢ [Documentation](#-documentation) ‚Ä¢ [Team](#-team)

</div>

---

## üìñ About The Project

This repository contains a complete autonomous driving stack developed for Formula Student Driverless (FSD) and Formula Student Autonomous (FSA) competitions. Our system enables a Formula Student race car to navigate unknown tracks at high speeds by detecting track boundaries, planning optimal trajectories, and executing precise vehicle control.

### üéØ Competition Objectives

- **Trackdrive**: Complete 10 laps of an unknown track as fast as possible
- **Autocross**: Navigate a complex track layout with optimal racing lines
- **Skidpad**: Execute figure-8 maneuvers demonstrating vehicle dynamics
- **Acceleration**: Straight-line speed test with autonomous control

---

## ‚ú® Key Features

- üéØ **Real-time Cone Detection** - YOLOv8-based vision system with LiDAR fusion
- üó∫Ô∏è **SLAM & Mapping** - Simultaneous localization and track boundary estimation
- üß≠ **Advanced Path Planning** - Delaunay triangulation with optimal racing line generation
- ‚ö° **Model Predictive Control** - High-frequency trajectory tracking at 100Hz
- üîÑ **Sensor Fusion** - Extended Kalman Filter combining IMU, GPS, and wheel odometry
- üñ•Ô∏è **Full Stack Simulation** - Gazebo integration for virtual testing and validation
- üìä **Real-time Visualization** - RViz dashboards for debugging and monitoring

---

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         PERCEPTION LAYER                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Camera     ‚îÇ    LiDAR     ‚îÇ     IMU      ‚îÇ    GPS/GNSS       ‚îÇ
‚îÇ  (YOLOv8)    ‚îÇ  (PCL/DBSCAN)‚îÇ              ‚îÇ                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ              ‚îÇ              ‚îÇ                ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ      SENSOR FUSION & LOCALIZATION       ‚îÇ
       ‚îÇ         (Extended Kalman Filter)        ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ          MAPPING & PERCEPTION           ‚îÇ
       ‚îÇ  ‚Ä¢ Cone Classification (Blue/Yellow)    ‚îÇ
       ‚îÇ  ‚Ä¢ Track Boundary Estimation            ‚îÇ
       ‚îÇ  ‚Ä¢ Occupancy Grid Mapping               ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ          PATH & MOTION PLANNING         ‚îÇ
       ‚îÇ  ‚Ä¢ Delaunay Triangulation               ‚îÇ
       ‚îÇ  ‚Ä¢ Minimum Curvature Trajectory         ‚îÇ
       ‚îÇ  ‚Ä¢ Velocity Profile Optimization        ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ         VEHICLE CONTROL LAYER           ‚îÇ
       ‚îÇ  ‚Ä¢ Model Predictive Control (MPC)       ‚îÇ
       ‚îÇ  ‚Ä¢ Pure Pursuit / Stanley Control       ‚îÇ
       ‚îÇ  ‚Ä¢ Longitudinal Speed Control           ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ  ACTUATORS  ‚îÇ
                   ‚îÇ Steer/Brake ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Repository Structure

```
fs-autonomous/
‚îú‚îÄ‚îÄ üìÇ perception/              # Sensor processing and object detection
‚îÇ   ‚îú‚îÄ‚îÄ camera/                 # Camera-based cone detection (YOLOv8)
‚îÇ   ‚îú‚îÄ‚îÄ lidar/                  # LiDAR point cloud processing
‚îÇ   ‚îú‚îÄ‚îÄ cone_detection/         # Multi-sensor fusion for cone detection
‚îÇ   ‚îî‚îÄ‚îÄ cone_classifier/        # Color classification (blue/yellow/orange)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ localization/            # State estimation and mapping
‚îÇ   ‚îú‚îÄ‚îÄ ekf/                    # Extended Kalman Filter implementation
‚îÇ   ‚îú‚îÄ‚îÄ slam/                   # Simultaneous Localization and Mapping
‚îÇ   ‚îî‚îÄ‚îÄ sensor_fusion/          # Multi-sensor data fusion algorithms
‚îÇ
‚îú‚îÄ‚îÄ üìÇ planning/                # Path and trajectory generation
‚îÇ   ‚îú‚îÄ‚îÄ path_planning/          # Global path generation (Delaunay/RRT)
‚îÇ   ‚îú‚îÄ‚îÄ trajectory/             # Trajectory optimization and smoothing
‚îÇ   ‚îî‚îÄ‚îÄ velocity_profile/       # Speed profile generation
‚îÇ
‚îú‚îÄ‚îÄ üìÇ control/                 # Vehicle control systems
‚îÇ   ‚îú‚îÄ‚îÄ mpc/                    # Model Predictive Controller
‚îÇ   ‚îú‚îÄ‚îÄ stanley/                # Stanley lateral controller
‚îÇ   ‚îú‚îÄ‚îÄ pure_pursuit/           # Pure Pursuit controller
‚îÇ   ‚îî‚îÄ‚îÄ pid/                    # PID controllers for speed/steering
‚îÇ
‚îú‚îÄ‚îÄ üìÇ simulation/              # Testing and validation environment
‚îÇ   ‚îú‚îÄ‚îÄ gazebo_worlds/          # Custom track models
‚îÇ   ‚îú‚îÄ‚îÄ vehicle_models/         # URDF/SDF vehicle descriptions
‚îÇ   ‚îî‚îÄ‚îÄ launch/                 # ROS 2 launch files
‚îÇ
‚îú‚îÄ‚îÄ üìÇ config/                  # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ params/                 # Algorithm parameters
‚îÇ   ‚îî‚îÄ‚îÄ calibration/            # Sensor calibration data
‚îÇ
‚îú‚îÄ‚îÄ üìÇ utils/                   # Utility functions and helpers
‚îÇ   ‚îú‚îÄ‚îÄ visualization/          # Plotting and visualization tools
‚îÇ   ‚îî‚îÄ‚îÄ data_processing/        # Data logging and analysis
‚îÇ
‚îú‚îÄ‚îÄ üìÇ tests/                   # Unit and integration tests
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docs/                    # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ setup_guide.md
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md
‚îÇ   ‚îú‚îÄ‚îÄ algorithms.md
‚îÇ   ‚îî‚îÄ‚îÄ competition_rules.md
‚îÇ
‚îú‚îÄ‚îÄ üìÑ requirements.txt         # Python dependencies
‚îú‚îÄ‚îÄ üìÑ package.xml              # ROS 2 package manifest
‚îú‚îÄ‚îÄ üìÑ CMakeLists.txt           # Build configuration
‚îî‚îÄ‚îÄ üìÑ README.md                # You are here!
```

---

## üöÄ Getting Started

### Prerequisites

- **Operating System**: Ubuntu 22.04 LTS (recommended)
- **ROS 2**: Humble Hawksbill
- **Python**: 3.8 or higher
- **C++ Compiler**: GCC 11+ with C++17 support

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-team/fs-autonomous.git
   cd fs-autonomous
   ```

2. **Install ROS 2 dependencies**
   ```bash
   sudo apt update
   rosdep install --from-paths . --ignore-src -r -y
   ```

3. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Build the workspace**
   ```bash
   colcon build --symlink-install
   source install/setup.bash
   ```

### Quick Start - Simulation

Launch the complete autonomous system in Gazebo:

```bash
# Terminal 1: Launch simulation environment
ros2 launch simulation autonomous_sim.launch.py

# Terminal 2: Start autonomous driving stack
ros2 launch fs_autonomous full_stack.launch.py

# Terminal 3: Visualize in RViz
ros2 launch fs_autonomous rviz.launch.py
```

---

## üß™ Testing

Run the complete test suite:

```bash
# Unit tests
colcon test --packages-select perception localization planning control

# Integration tests
colcon test --packages-select fs_autonomous

# View test results
colcon test-result --verbose
```

---

## üìä Performance Metrics

| Metric | Target | Current Status |
|--------|--------|----------------|
| Cone Detection Rate | >95% | üü¢ 97.3% |
| Localization Accuracy | <10cm RMS | üü¢ 8.2cm |
| Planning Frequency | >20Hz | üü¢ 25Hz |
| Control Frequency | >100Hz | üü¢ 120Hz |
| Max Speed (Simulation) | 80 km/h | üü° 72 km/h |
| Lap Time Consistency | <5% variance | üü° Work in progress |

---

## üìö Documentation

Detailed documentation is available in the [`docs/`](docs/) directory:

- **[System Architecture](docs/architecture.md)** - Detailed component breakdown
- **[Algorithm Details](docs/algorithms.md)** - Mathematical formulations
- **[Setup Guide](docs/setup_guide.md)** - Hardware and software setup
- **[Competition Rules](docs/competition_rules.md)** - FSD/FSA regulations
- **[API Reference](docs/api_reference.md)** - Code documentation

---

## üõ†Ô∏è Tech Stack

### Core Technologies
- **ROS 2 Humble** - Robotics middleware framework
- **Python 3.8+** - High-level algorithm development
- **C++17** - Performance-critical components
- **CMake** - Build system

### Key Libraries
- **Computer Vision**: OpenCV, YOLOv8, PyTorch
- **Point Cloud**: PCL (Point Cloud Library)
- **Optimization**: CasADi, OSQP, SciPy
- **Mathematics**: NumPy, Eigen3
- **Simulation**: Gazebo Classic, RViz
- **Testing**: pytest, Google Test

---

## üó∫Ô∏è Roadmap

### Phase 1: Foundation ‚úÖ
- [x] Basic ROS 2 architecture
- [x] Simulation environment setup
- [x] Simple cone detection

### Phase 2: Core Systems üöß
- [x] Sensor fusion pipeline
- [x] Path planning algorithms
- [ ] MPC controller implementation
- [ ] Real vehicle integration

### Phase 3: Optimization üìã
- [ ] Deep learning cone detection
- [ ] Advanced SLAM algorithms
- [ ] Racing line optimization
- [ ] Real-time performance tuning

### Phase 4: Competition Ready üìã
- [ ] Full safety systems
- [ ] Emergency brake logic
- [ ] Competition validation
- [ ] On-track testing

---

## ü§ù Contributing

We welcome contributions from team members! Please follow these guidelines:

1. Create a feature branch: `git checkout -b feature/amazing-feature`
2. Follow our coding standards (see `docs/coding_standards.md`)
3. Write tests for new functionality
4. Commit with clear messages: `git commit -m "Add amazing feature"`
5. Push to your branch: `git push origin feature/amazing-feature`
6. Open a Pull Request

---

## üë• Team

**Formula Student Autonomous Team**

- üèÜ Team Lead: [Name]
- üéØ Perception Lead: [Name]
- üó∫Ô∏è Localization Lead: [Name]
- üß≠ Planning Lead: [Name]
- ‚öôÔ∏è Controls Lead: [Name]
- üíª Software Lead: [Name]

### Acknowledgments

Special thanks to:
- Formula Student community for open-source resources
- Our university and sponsors
- All team members and contributors

---

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üìß Contact

For questions or collaboration opportunities:

- **Email**: team@fs-autonomous.com
- **Website**: [your-team-website.com]
- **Instagram**: [@your_team_handle]

---

<div align="center">

**‚≠ê Star this repository if you find it helpful!**

Made with ‚ù§Ô∏è by the Formula Student Autonomous Team

</div>


